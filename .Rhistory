y <- matrix (1:20, nrow = 5, ncol = 4)
y
cells <- c(1,26,24,68)
cells
patientID <- c(1, 2, 3, 4)
age <- c(25, 34, 28, 52)
diabetes <- c("Type1", "Type2", "Type1", "Type1")
status <- c("Poor", "Improved", "Excellent", "Poor")
patientdata <- data.frame(patientID, age, diabetes, status)
patientdata
names(patientdata)
patientdata[1:2]
patientdata[1]
patientdata[, 1]
class(patientdata[1:2])
class(patientdata[, 1])
patientdata$patientID
patientdata[, patientdata$age]
class(patientdata[, c(1)])
class(patientdata[, c(1,2)])
class(patientdata[, 1:2])
?runif
runif(10)
runif(10, min=1, max=2)
?rnom
?rnorm
rnorm(2)
rnorm(10)
?lapply
x <- list(a=1:5, b= rnorm(10))
x
lapply(x, mean)
?runif
x <- list(a=matrix(1:4,2,2), b= matrix(1:6, 3, 2))
x
lapply(x, function(elt) elt[,1])
lapply(x, function(func) func[,1])
?apply
x <- matrix(rnorm(200), 20,10)
x
apply(x, 2, mean)
mean(x[1,])
mean(x[,1])
?rep
gl?
(1,1)
gl(1,2)
gl(2,2)
gl(4,2)
library(datasets)
data("iris")
?iris
vir<- subset(iris, iris$Species=="virginica")
vir
mean(vir$Sepal.Length)
split(iris, iris$Species)
sapply(split(iris, iris$Species),mean)
sapply(split(iris$Sepal.Length, iris$Species),mean)
lapply(split(iris$Sepal.Length, iris$Species),mean)
apply(iris[,1:4]),1,mean)
apply(iris[,1:4],1,mean)
apply(iris[,1:4],2,mean)
colMeans(iris)
?colMeans
data("mtcars")
head(mtcards)
head(mtcars)
with(mtcars,tapply(mpg,cyl,mean))
with(mtcars, tapply(hp, cyl, mean))
x <- with(mtcars, tapply(hp, cyl, mean))
x
class(x)
x[2]-x[0]
x[3]-x[1]
debug(ls)
ls
d
?quantile
mid <- c(7921,5184,8836,4761)
m <- mean(c)
m
m <- mean(mid)
m
maxmin <- 8836-4761
x2 <- (5184-m)/maxmin
x2
maxmin
(4761-m)/maxmin
(5184-m)/maxmin
mid <- c(89,72,94,69)
m <- mean(mid)
m
maxmin <- 94-69
(94-m)/maxmin
## Put comments here that give an overall description of what your
## functions do
## Write a short comment describing this function
makeCacheMatrix <- function(m = matrix()) {
inverse_m <- NULL
set <- function(y) {
m <<- y
inverse_m <<- NULL
}
get <- function() m
setinverse <- function(inverse) inverse_m <<- inverse
getinverse <- function() inverse_m
list(set = set, get = get,
setinverse = setinverse,
getinverse = getinverse)
}
## Write a short comment describing this function
cacheSolve <- function(m, ...) {
inverse_m <- m$getinverse()
if(!is.null(inverse_m)) {
message("getting cached data")
return(inverse_m)
}
data <- m$get()
inverse_m <- solve(data, ...)
m$setinverse(inverse_m)
inverse_m
}
makeCacheMatrix(matrix(1:4,2,2))
m <- makeCacheMatrix(matrix(1:4,2,2))
m$get()
m$getinverse()
cacheSolve(m)
cacheSolve(m)
git config --global user.name "Khanh Nguyen"
install.packages("caret")
require(caret)
data("segmentationData")
segmentationData$Cell <- NULL
data("segmentationData")
segmentationData$Cell <- NULL
training <- subset(segmentationData, Case="Train")
testing <- subset(segmentationData, Case="Test")
training$Case <- NULL
testing$Case <- NULL
str(training[, 1:6])
trainX <- training[, names(training)!="Class"]
preProcValues <- preProcess(trainX, method = c("center", "scale"))
preProcValues
scaledTrain <- predict(preProcValues, trainX)
library(rpart)
rpart1 <- rpart(class ~ ., data = training, control = rpart.control(maxdepth = 2))
scaledTrain <- predict(preProcValues, trainX)
class(training)
rpart1 <- rpart(class ~ ., data = training, control = rpart.control(maxdepth = 2))
rpart1 <- rpart(Class ~ ., data = training, control = rpart.control(maxdepth = 2))
rpart1
rpart1a <- as.party(rpart1)
library(rpart)
install.packages(partykit)
install.packages("partykit")
library(partykit)
rpart1a <- as.party(rpart1)
plot(rpart1a)
rpartFull <- rpart(Class ~ ., data=training)
rpartFull
rpartPred <- predict(rpartFull, testing, type="class")
confusionMatrix(rpartPred, testing$Class) # requires 2 factor vectors
install.packages("e1071")
rpartPred <- predict(rpartFull, testing, type="class")
confusionMatrix(rpartPred, testing$Class) # requires 2 factor vectors
train(Class ~ ., data = training, method="rpart")
train(Class ~ ., data = training, method="rpart", tuneLength=30)
cvCtrl <- trainControl(method = "repeatedcv", repeats = 3)
train(Class ~ ., data = training, method="rpart", tuneLength=30, trControl=cvCtrl)
cvCtrl <- trainControl(method = "repeatedcv", repeats = 3,
summaryFunction = twoClassSummary,
classProbs = TRUE)
set.seed(1)
rpartTune <- train(Class ~ ., data = training, method = "rpart",
tuneLength = 30,
metric = "ROC",
trControl = cvCtrl)
install.packages("pROC")
require(pROC)
cvCtrl <- trainControl(method = "repeatedcv", repeats = 3,
summaryFunction = twoClassSummary,
classProbs = TRUE)
set.seed(1)
rpartTune <- train(Class ~ ., data = training, method = "rpart",
tuneLength = 30,
metric = "ROC",
trControl = cvCtrl)
rpartTune
plot(rpartTune, scales = list(x = list(log = 10)))
rpartPred2 <- predict(rpartTune, testing)
confusionMatrix(rpartPred2, testing$Class)
rpartProbs <- predict(rpartTune, testing, type = "prob")
head(rpartProbs)
library(pROC)
rpartROC <- roc(testing$Class, rpartProbs[, "PS"], levels = rev(testProbs$Class))
plot(rpartROC, type = "S", print.thres = .5)
rpartROC
rpartProbs <- predict(rpartTune, testing, type = "prob")
head(rpartProbs)
C50(x = predictors, y = factorOutcome)
install.packages("mboost")
library(mboost)
C50(x = predictors, y = factorOutcome)
grid <- expand.grid(.model = "tree",
.trials = c(1:100),
.winnow = FALSE)
c5Tune <- train(trainX, training$Class,
method = "C5.0",
metric = "ROC",
tuneGrid = grid,
trControl = cvCtrl)
library(plyr)
c5Tune <- train(trainX, training$Class,
method = "C5.0",
metric = "ROC",
tuneGrid = grid,
trControl = cvCtrl)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data("segmentationOriginal")
install.packages("sparkR")
library(AppliedPredictiveModeling)
data("segmentationOriginal")
segData <- subset(segmentationOriginal, Case = "Train")
cellID <- segData$Cell
class <- segData$Class
case <- segData$Case
segData <- segData[, -(1:3)]
statusColNum
statusColNum <- grep("Status", names(segData))
statusColNum
segData <- segData[, -statusColNum]
library(e1071)
skewness(segData$AngleCh1)
skewValues <- apply(segData, 2, skewness)
head(skewValues
)
library(caret)
Ch1AreaTrans <- BoxCoxTrans(segData$AreaCh1)
Ch1AreaTrans
head(segData$AreaCh1)
predict(Ch1AreaTrans, head(segData$AngleCh1))
plot(segData$AngleCh1)
plot(segData$AngleCh1, type = "b")
plot(segData$AngleCh1, type = "h")
hist(segData$AngleCh1)
pcaObject <- prcomp(segData, center = T, scale. = T)
percentVariance <- pcaObject$sdev^2/sum(pcaObject$sdev^2)*100
percentVariance[1:3]
head(pcaObject$x[,1:5])
head(pcaObject$rotation[,1:5])
trans <- preProcess(segData, method = c("BoxCode", "center", "scale", "pca"))
trans <- preProcess(segData, method = c("BoxCox", "center", "scale", "pca"))
trans
transformed <- predict(trans, segData)
head(transformed[, 1:5])
nearZeroVar(segData)
correlations <- cor(segData)
dim(correlations)
correlations[1:4,1:4]
library(corrplot)
install.packages("corrplot")
library(corrplot)
corrplot(correlations,order="hclust")
highCorr <- findCorrelation(correlations, cutoff=.75)
length(highCorr)
head(highCorr)
filteredSegData <- segData[, -highCorr]
str(filteredSegData)
head(carSubSet)
head(carSubset)
library(caret)
cars
cars
library(AppliedPredictiveModeling)
data(twoClassData)
str(predictors)
trainingRows <- crateDataPartition(classes, p=.80, list=F)
trainingRows <- createDataPartition(classes, p=.80, list=F)
set.seed(1)
trainingRows <- createDataPartition(classes, p=.80, list=F)
head(trainingRows)
trainPredictors <- predictors[trainingRows,]
trainClasses <- classes[traningRows]
trainClasses <- classes[trainingRows]
testPredictors <- predictors[-trainingRows,]
testClasses <- classes[-trainingRows]
str(trainPredictors)
str(testPredictors)
set.seed(1)
repeatedSplits <- createDataPartition(trainClasses,p=.80,times=3)
str(repeatedSplits)
set.seed(1)
cvSplits <- createFolds(trainClasses, k=10, returnTrain = T)
str(cvSplits)
fold1 <- cvSplits[[1]]
cvPredictors1 <- trainPredictors[fold1,]
cvClasses1 <- trainClasses[fold1]
nrow(trainPredictors)
nrow(cvPredictors1)
modelFunction(price ~ numBedrooms+numBaths+acres),datat=housingData)
trainPredictors <- as.matrix(trainPredictors)
knnFit <- knn3(x=trainPredictors,y=trainClasses,k=5)
knnFit
testPredictors <- predict(knnFit, newdata = testPredictors, type="class")
head(testPredictors)
str(testpre)
str(testPredictors)
data("GermanCredit")
set.seed(1056)
svmFit<- train(Class~ .,data=GermanCredit, method="svmRadial")
svmFit<- train(Class~ .,data=GermanCredit, method="svmRadial")
str(GermanCreditTrain)
GermanCreditTrain
library(AppliedPredictiveModeling)
GermanCreditTrain
library(AppliedPredictiveModeling::getPackages(chapter = 4))
GermanCredit <- GermanCredit[, -nearZeroVar(GermanCredit)]
GermanCredit$CheckingAccountStatus.lt.0 <- NULL
GermanCredit$SavingsAccountBonds.lt.100 <- NULL
GermanCredit$EmploymentDuration.lt.1 <- NULL
GermanCredit$EmploymentDuration.Unemployed <- NULL
GermanCredit$Personal.Male.Married.Widowed <- NULL
GermanCredit$Property.Unknown <- NULL
GermanCredit$Housing.ForFree <- NULL
set.seed(100)
inTrain <- createDataPartition(GermanCredit$Class, p=.8)[[1]]
inTrain
GermanCreditTrain <- GermanCredit[inTrain,]
GermanCreditTest <- GermanCredit[-inTrain,]
set.seed(1056)
svmFit <- train(Class ~ ., data=GermanCreditTrain, method="svmRadial",preProc=c("center","scale"),tuneLength=10)
svmFit <- train(Class ~ ., data=GermanCreditTrain, method="svmRadial",preProc=c("center","scale"),tuneLength=10, trControl=trainControl(method="repeatedcv",repeat=5))
svmFit <- train(Class ~ ., data=GermanCreditTrain, method="svmRadial",preProc=c("center","scale"),tuneLength=10, trControl=trainControl(method="repeatedcv",repeats=5))
svmFit
plot(svmFit, scales=list(x=list(log=2)))
predictedClasses <- predict(svmFit, GermanCreditTest)
str(predictedClasses)
predictedProbs <- predict(svmFit, newdata=GermanCreditTest,type="prob")
predictedProbs <- predict(svmFit, newdata=GermanCreditTest)
predictedProbs <- predict(svmFit, newdata=GermanCreditTest, type="prob"
)
?predict
set.seed(1056)
logisticReg <- train(Class ~ ., data=GermanCreditTrain, method="glm",
trControl=trainControl(method = "repeatedcv",repeats=5)
)
logisticReg
resamp <- resamples(list=(SVM=svmFit, Logistic=logisticReg))
resamp <- resamples(list(SVM=svmFit, Logistic=logisticReg))
resamp
summary(resamp)
modelDifferences <- diff(resamp)
summary(modelDifferences)
rfe?
?rfe
library(AppliedPredictiveModeling)
data(twoClassData)
str(predictors)
str(classes)
set.seed(1)
library(caret)
trainingRows <- createDataPartition(classes, p = .8, list = F)
head(trainingRows)
trainPredictors <- predictors[trainingRows,]
trainClasses <- classes[trainingRows,]
trainClasses <- classes[trainingRows]
testPredictors <- predictors[-trainingRows,]
testClasses <- classes[-trainingRows]
str(trainPredictors)
library(swirl)
swirl()
install_from_swirl("Statistical Inference")
swirl()
swirl()
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
weighted.mean(x,w)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
lm(y ~ 0 + x)$coeff
data(mtcars)
fit <- lm(mpg ~ wt, mtcars)
summary(fit) # -5.3445
swirl()
swirl
library(swirl)
swirl()
a
swirl()
swirl()
swirl()
library(ggplot2)
swirl()
33/36
deck
52
4/52
0
12/52
3/51
2/51
1.6*.8
1.6*.8/2
.64
mypdf
mypdf(1.6)
integrate(mypdf,0,1.6)
.8
2
info()
1
sqrt(2)
pnorm(70, mean=80, sd=10)
library(swirl)
swirl()
dice_sqr
ex2_fair <- dice_sqr*dice_fair
ex2_fair <- sum(dice_sqr*dice_fair)
ex2_fair - 3.5^2
abline(fit,col="red")
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
fit<-lm(y~x)
est<-predict(fit,data.frame(x))
plot(x,y)
abline(fit,col="red")
summary(fit)
# Problem 3.
data(mtcars)
x<-mtcars$wt
y<-mtcars$mpg
fit<-lm(y ~ x)
predict(fit,data.frame(x=mean(x)), interval="confidence")
infor()
info()
exit
exit()
setwd("D:/coursera/ReproducableResearch/repdata-data-activity/")
setwd("C:/Users/Khanh/RepData_PeerAssessment1/")
